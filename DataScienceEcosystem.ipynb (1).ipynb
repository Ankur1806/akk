{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0105EN-SkillsNetwork/labs/Module2/images/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add your code below following the instructions given in the course\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Tools and Ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, Data Science Tools and Ecosystem are summarized.\n",
    "The data science ecosystem encompasses a rich variety of tools facilitating every stage of the data analysis pipeline. From initial data collection and cleaning using libraries like Pandas and R's Tidyverse, to storage and management with SQL or NoSQL databases and data lakes, and visualization aided by Matplotlib and D3.js, the ecosystem is robust. Machine learning tasks are supported by libraries such as Scikit-learn and TensorFlow, while big data processing is handled by frameworks like Hadoop and Spark. Model deployment finds solutions in platforms like SageMaker and MLflow, while collaboration thrives on platforms like Jupyter and GitHub. Automated machine learning tools like DataRobot and Auto-sklearn streamline model development, while NLP tasks benefit from libraries like NLTK and spaCy. Time series analysis is facilitated by Statsmodels and Prophet, with experiment tracking aided by platforms like Neptune.ai and Weights & Biases. Workflow automation is managed through platforms like Apache Airflow and Prefect, and model interpretability is addressed by tools like SHAP and Lime. Graph analysis finds its place with libraries like NetworkX and igraph. These tools collectively contribute to the efficiency and effectiveness of data science endeavors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives**:\n",
    "Certainly, here are the key objectives of data science:\n",
    "\n",
    "+ Data Exploration and Understanding\n",
    "+ Data Cleaning and Preparation\n",
    "+ Predictive Modeling and Inference\n",
    "+ Insight Generation and Interpretation\n",
    "+ Model Deployment and Integration\n",
    "+ Continuous Improvement and Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the popular languages that Data Scientists use are:\n",
    "1. Python\n",
    "2. R\n",
    "3. Java\n",
    "4. Java Script\n",
    "5. Scala \n",
    "6. C++\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the commonly used libraries used by Data Scientists include:\n",
    "Certainly! Here are some commonly used libraries by data scientists across various programming languages:\n",
    "\n",
    "**Python:**\n",
    "1. Pandas: For data manipulation and analysis.\n",
    "2. NumPy: For numerical computing and arrays.\n",
    "3. Matplotlib: For creating static, animated, and interactive visualizations in Python.\n",
    "4. TensorFlow: An open-source machine learning framework for tasks likedeep learning and neural networks.\n",
    "\n",
    "**R:**\n",
    "1. Tidyverse: A collection of R packages for data science, including ggplot2 for visualization, dplyr for data manipulation, and tidyr for data tidying.\n",
    "2. caret: A comprehensive framework for building machine learning models in R.\n",
    "3. ggplot2: A popular R package for data visualization, based on the grammar of graphics.\n",
    "4. dplyr: For data manipulation tasks, especially for working with data frames.\n",
    "5. tidyr: For tidying and reshaping data.\n",
    "\n",
    "These libraries form the backbone of data science workflows in Python and R, offering powerful tools for data manipulation, visualization, statistical analysis, machine learning, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Science Tools |\n",
    "| --------------------|\n",
    "| Jupyter Notebook |\n",
    "| R Studio |\n",
    "| Google Collaborative |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are a few examples of evaluating arithmetic expressions in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This a simple arithmetic expression to mutiply then add integers\n",
    "(3*4)+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333333333335"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will convert 200 minutes to hours by diving by 60\n",
    "200/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Author\n",
    "   Ankur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
